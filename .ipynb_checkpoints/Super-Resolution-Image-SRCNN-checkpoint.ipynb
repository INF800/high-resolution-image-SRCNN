{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper can be found here http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]\n",
      "Keras: 2.2.4\n",
      "OpenCV: 4.1.0\n",
      "NumPy: 1.16.2\n",
      "Matplotlib: 3.0.3\n",
      "Scikit-Image: 0.14.2\n"
     ]
    }
   ],
   "source": [
    "# check package versions\n",
    "import sys\n",
    "import keras\n",
    "import cv2\n",
    "import numpy\n",
    "import matplotlib\n",
    "import skimage\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Keras: {}'.format(keras.__version__))\n",
    "print('OpenCV: {}'.format(cv2.__version__))\n",
    "print('NumPy: {}'.format(numpy.__version__))\n",
    "print('Matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('Scikit-Image: {}'.format(skimage.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# python magic function, displays pyplot figures in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image quality metrics\n",
    "\n",
    "# define a function for peak signal-to-noise ratio (PSNR)\n",
    "# Higer the better\n",
    "def psnr(target, ref):\n",
    "         \n",
    "    # assume RGB image\n",
    "    target_data = target.astype(float)\n",
    "    ref_data = ref.astype(float)\n",
    "\n",
    "    diff = ref_data - target_data\n",
    "    diff = diff.flatten('C')\n",
    "\n",
    "    rmse = math.sqrt(np.mean(diff ** 2.))\n",
    "\n",
    "    return 20 * math.log10(255. / rmse)\n",
    "\n",
    "# define function for mean squared error (MSE)\n",
    "# Lower the error more similar to original image\n",
    "def mse(target, ref):\n",
    "    # the MSE between the two images is the sum of the squared difference between the two images\n",
    "    err = np.sum((target.astype('float') - ref.astype('float')) ** 2)\n",
    "    err /= float(target.shape[0] * target.shape[1])\n",
    "    \n",
    "    return err\n",
    "\n",
    "# ssim stands for Structural Similarity and we are importing it directly from skimage\n",
    "# It tells how similar two images are. '1' being exactly similar\n",
    "\n",
    "# define function that combines all three image quality metrics\n",
    "def compare_images(target, ref):\n",
    "    scores = []\n",
    "    scores.append(psnr(target, ref))\n",
    "    scores.append(mse(target, ref))\n",
    "    scores.append(ssim(target, ref, multichannel =True))\n",
    "    \n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare degraded images by introducing quality distortions via resizing\n",
    "\n",
    "# 'factor' is the measure to which we will alter the image in 'path'\n",
    "def prepare_images(path, factor):\n",
    "    \n",
    "    # loop through the files in the directory\n",
    "    for file in os.listdir(path):\n",
    "        \n",
    "        # open the file\n",
    "        img = cv2.imread(path + '/' + file)\n",
    "        \n",
    "        # find old and new image dimensions\n",
    "        h, w, _ = img.shape\n",
    "        new_height = int( h / factor )\n",
    "        new_width = int( w / factor )\n",
    "        \n",
    "        # resize the image - down\n",
    "        img = cv2.resize(img, (new_width, new_height), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        # resize the image - up\n",
    "        img = cv2.resize(img, (w, h), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        # save the image\n",
    "        print('Saving {}'.format(file))\n",
    "        cv2.imwrite('images/{}'.format(file), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving baboon.bmp\n",
      "Saving baby_GT.bmp\n",
      "Saving barbara.bmp\n",
      "Saving bird_GT.bmp\n",
      "Saving butterfly_GT.bmp\n",
      "Saving coastguard.bmp\n",
      "Saving comic.bmp\n",
      "Saving face.bmp\n",
      "Saving flowers.bmp\n",
      "Saving foreman.bmp\n",
      "Saving head_GT.bmp\n",
      "Saving lenna.bmp\n",
      "Saving monarch.bmp\n",
      "Saving pepper.bmp\n",
      "Saving ppt3.bmp\n",
      "Saving woman_GT.bmp\n",
      "Saving zebra.bmp\n"
     ]
    }
   ],
   "source": [
    "# distorting the image\n",
    "prepare_images('source/', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baboon.bmp\n",
      "PSNR: 20.051808002302312\n",
      "MSE: 1927.6173\n",
      "SSIM: 0.5006928299822372\n",
      "\n",
      "baby_GT.bmp\n",
      "PSNR: 31.69723520103162\n",
      "MSE: 131.97087478637695\n",
      "SSIM: 0.8883361032967249\n",
      "\n",
      "barbara.bmp\n",
      "PSNR: 23.447393065729266\n",
      "MSE: 881.9872540509259\n",
      "SSIM: 0.73065294994638\n",
      "\n",
      "bird_GT.bmp\n",
      "PSNR: 29.79135363470666\n",
      "MSE: 204.6756847993827\n",
      "SSIM: 0.9128571831791062\n",
      "\n",
      "butterfly_GT.bmp\n",
      "PSNR: 22.006520728495104\n",
      "MSE: 1228.9933776855469\n",
      "SSIM: 0.797964951530857\n",
      "\n",
      "coastguard.bmp\n",
      "PSNR: 24.189445957446942\n",
      "MSE: 743.4589942392677\n",
      "SSIM: 0.6096745582108661\n",
      "\n",
      "comic.bmp\n",
      "PSNR: 21.16826542909264\n",
      "MSE: 1490.6479002770084\n",
      "SSIM: 0.7093499981550738\n",
      "\n",
      "face.bmp\n",
      "PSNR: 28.747257347129583\n",
      "MSE: 260.3010265700483\n",
      "SSIM: 0.7185510464651969\n",
      "\n",
      "flowers.bmp\n",
      "PSNR: 24.88592275321631\n",
      "MSE: 633.2997845303868\n",
      "SSIM: 0.7894223069949616\n",
      "\n",
      "foreman.bmp\n",
      "PSNR: 27.103603466719377\n",
      "MSE: 380.05046559343435\n",
      "SSIM: 0.8865113978857826\n",
      "\n",
      "head_GT.bmp\n",
      "PSNR: 29.4934009109717\n",
      "MSE: 219.2105867346939\n",
      "SSIM: 0.7397452965417933\n",
      "\n",
      "lenna.bmp\n",
      "PSNR: 29.225056634222412\n",
      "MSE: 233.18249893188477\n",
      "SSIM: 0.7874679514772224\n",
      "\n",
      "monarch.bmp\n",
      "PSNR: 27.39136061916819\n",
      "MSE: 355.68500264485675\n",
      "SSIM: 0.9074863554787265\n",
      "\n",
      "pepper.bmp\n",
      "PSNR: 27.191978538830448\n",
      "MSE: 372.3949317932129\n",
      "SSIM: 0.7906274751621787\n",
      "\n",
      "ppt3.bmp\n",
      "PSNR: 21.777169198186918\n",
      "MSE: 1295.6410392364794\n",
      "SSIM: 0.8746673351446219\n",
      "\n",
      "woman_GT.bmp\n",
      "PSNR: 26.403067176767557\n",
      "MSE: 446.5755048959608\n",
      "SSIM: 0.8817739206939175\n",
      "\n",
      "zebra.bmp\n",
      "PSNR: 24.562722751198148\n",
      "MSE: 682.2276869495387\n",
      "SSIM: 0.7871264399208598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test the generated images using the image quality metrics\n",
    "\n",
    "for file in os.listdir('images/'):\n",
    "    \n",
    "    # open target and reference images\n",
    "    target = cv2.imread('images/{}'.format(file))\n",
    "    ref = cv2.imread('source/{}'.format(file))\n",
    "    \n",
    "    # calculate score\n",
    "    scores = compare_images(target, ref)\n",
    "\n",
    "    # print all three scores with new line characters (\\n) \n",
    "    print('{}\\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(file, scores[0], scores[1], scores[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the SRCNN model\n",
    "\n",
    "# note that input_shape is (None, None, 1) which means it will work on image with ANY height or weight but needs \n",
    "# only one channel! This is also because SRCNN was trained on YCrCb color space in paper (srcnn trained on Y channel). So we have to convert \n",
    "# into that channel and feed it.\n",
    "\n",
    "def model():\n",
    "    \n",
    "    # define model type\n",
    "    SRCNN = Sequential()\n",
    "    \n",
    "    # add model layers\n",
    "    SRCNN.add(Conv2D(filters=128, kernel_size = (9, 9), kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='valid', use_bias=True, input_shape=(None, None, 1)))\n",
    "    SRCNN.add(Conv2D(filters=64, kernel_size = (3, 3), kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='same', use_bias=True))\n",
    "    SRCNN.add(Conv2D(filters=1, kernel_size = (5, 5), kernel_initializer='glorot_uniform',\n",
    "                     activation='linear', padding='valid', use_bias=True))\n",
    "    \n",
    "    # define optimizer\n",
    "    adam = Adam(lr=0.0003)\n",
    "    \n",
    "    # compile model\n",
    "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    \n",
    "    return SRCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/MarkPrecursor/SRCNN-keras find precomputed weights in 3051crop_weight_200.h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary image processing functions\n",
    "\n",
    "# makes image width and height divisible by some scale\n",
    "def modcrop(img, scale):\n",
    "    tmpsz = img.shape     # temp size\n",
    "    sz = tmpsz[0:2]\n",
    "    sz = sz - np.mod(sz, scale) # ensures dimensions of image are divisible by certain scale\n",
    "    img = img[0:sz[0], 1:sz[1]]\n",
    "    return img\n",
    "\n",
    "\n",
    "# cropping off border size\n",
    "def shave(image, border):\n",
    "    img = image[border: -border, border: -border]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define main prediction function\n",
    "\n",
    "def predict(image_path):\n",
    "    \n",
    "    # load the precomputed srcnn model with weights\n",
    "    srcnn = model()\n",
    "    srcnn.load_weights('3051crop_weight_200.h5')\n",
    "    \n",
    "    # load the degraded and reference images\n",
    "    # split directory name and path separaytely\n",
    "    path, file = os.path.split(image_path)\n",
    "    degraded = cv2.imread(image_path)\n",
    "    ref = cv2.imread('source/{}'.format(file))\n",
    "    \n",
    "    # preprocess the image with modcrop\n",
    "    ref = modcrop(ref, 3)\n",
    "    degraded = modcrop(degraded, 3)\n",
    "    \n",
    "    # convert the image to YCrCb - (srcnn trained on Y channel)\n",
    "    temp = cv2.cvtColor(degraded, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # create image slice and normalize  \n",
    "    Y = numpy.zeros((1, temp.shape[0], temp.shape[1], 1), dtype=float)\n",
    "    Y[0, :, :, 0] = temp[:, :, 0].astype(float) / 255\n",
    "    \n",
    "    # perform super-resolution with srcnn\n",
    "    pre = srcnn.predict(Y, batch_size=1)\n",
    "    \n",
    "    # post-process output\n",
    "    pre *= 255\n",
    "    pre[pre[:] > 255] = 255\n",
    "    pre[pre[:] < 0] = 0\n",
    "    pre = pre.astype(np.uint8)\n",
    "    \n",
    "    # copy Y channel back to image and convert to BGR\n",
    "    temp = shave(temp, 6)\n",
    "    temp[:, :, 0] = pre[0, :, :, 0]\n",
    "    output = cv2.cvtColor(temp, cv2.COLOR_YCrCb2BGR)\n",
    "    \n",
    "    # remove border from reference and degraged image\n",
    "    ref = shave(ref.astype(np.uint8), 6)\n",
    "    degraded = shave(degraded.astype(np.uint8), 6)\n",
    "    \n",
    "    # image quality calculations\n",
    "    scores = []\n",
    "    scores.append(compare_images(degraded, ref))\n",
    "    scores.append(compare_images(output, ref))\n",
    "    \n",
    "    # return images and scores\n",
    "    return ref, degraded, output, scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
